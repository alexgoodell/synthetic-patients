{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# pip install langchain\n",
    "# pip install arxiv\n",
    "# pip install wikipedia\n",
    "# pip install duckduckgo-search\n",
    "# pip install -U langsmith\n",
    "# pip install openai\n",
    "# pip install google-search-results\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "llm = OpenAI(temperature=0,model_name='gpt-4')\n",
    "from uuid import uuid4\n",
    "\n",
    "unique_id = uuid4().hex[0:8]\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"Agent_2_Agent\"\n",
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "\n",
    "from typing import List, Dict, Callable\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    BaseMessage,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DialogueAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "    ) -> None:\n",
    "        self.name = name\n",
    "        self.system_message = system_message\n",
    "        self.model = model\n",
    "        self.prefix = f\"{self.name}: \"\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.message_history = [\"Here is the conversation so far.\"]\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Applies the chatmodel to the message history\n",
    "        and returns the message string\n",
    "        \"\"\"\n",
    "        message = self.model(\n",
    "            [\n",
    "                self.system_message,\n",
    "                HumanMessage(content=\"\\n\".join(self.message_history + [self.prefix])),\n",
    "            ]\n",
    "        )\n",
    "        return message.content\n",
    "\n",
    "    def receive(self, name: str, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Concatenates {message} spoken by {name} into message history\n",
    "        \"\"\"\n",
    "        self.message_history.append(f\"{name}: {message}\")\n",
    "\n",
    "\n",
    "class DialogueSimulator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agents: List[DialogueAgent],\n",
    "        selection_function: Callable[[int, List[DialogueAgent]], int],\n",
    "    ) -> None:\n",
    "        self.agents = agents\n",
    "        self._step = 0\n",
    "        self.select_next_speaker = selection_function\n",
    "\n",
    "    def reset(self):\n",
    "        for agent in self.agents:\n",
    "            agent.reset()\n",
    "\n",
    "    def inject(self, name: str, message: str):\n",
    "        \"\"\"\n",
    "        Initiates the conversation with a {message} from {name}\n",
    "        \"\"\"\n",
    "        for agent in self.agents:\n",
    "            agent.receive(name, message)\n",
    "\n",
    "        # increment time\n",
    "        self._step += 1\n",
    "\n",
    "    def step(self) -> tuple[str, str]:\n",
    "        # 1. choose the next speaker\n",
    "        speaker_idx = self.select_next_speaker(self._step, self.agents)\n",
    "        speaker = self.agents[speaker_idx]\n",
    "\n",
    "        # 2. next speaker sends message\n",
    "        message = speaker.send()\n",
    "\n",
    "        # 3. everyone receives message\n",
    "        for receiver in self.agents:\n",
    "            receiver.receive(speaker.name, message)\n",
    "\n",
    "        # 4. increment time\n",
    "        self._step += 1\n",
    "\n",
    "        return speaker.name, message\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffc27abc51ce225f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DialogueAgentWithTools(DialogueAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "        tool_names: List[str],\n",
    "        **tool_kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(name, system_message, model)\n",
    "        self.tools = load_tools(tool_names, **tool_kwargs)\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Applies the chatmodel to the message history\n",
    "        and returns the message string\n",
    "        \"\"\"\n",
    "        agent_chain = initialize_agent(\n",
    "            self.tools,\n",
    "            self.model,\n",
    "            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            memory=ConversationBufferMemory(\n",
    "                memory_key=\"chat_history\", return_messages=True\n",
    "            ),\n",
    "        )\n",
    "        message = AIMessage(\n",
    "            content=agent_chain.run(\n",
    "                input=\"\\n\".join(\n",
    "                    [self.system_message.content] + self.message_history + [self.prefix]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return message.content"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af0d004def041e8e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"AI accelerationist\": [\"arxiv\", \"ddg-search\", \"wikipedia\"],\n",
    "    \"AI alarmist\": [\"arxiv\", \"ddg-search\", \"wikipedia\"],\n",
    "}\n",
    "topic = \"The current impact of automation and artificial intelligence on employment\"\n",
    "word_limit = 50  # word limit for task brainstorming"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29225a1ea01c3c0b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "conversation_description = f\"\"\"Here is the topic of conversation: {topic}\n",
    "The participants are: {', '.join(names.keys())}\"\"\"\n",
    "\n",
    "agent_descriptor_system_message = SystemMessage(\n",
    "    content=\"You can add detail to the description of the conversation participant.\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_agent_description(name):\n",
    "    agent_specifier_prompt = [\n",
    "        agent_descriptor_system_message,\n",
    "        HumanMessage(\n",
    "            content=f\"\"\"{conversation_description}\n",
    "            Please reply with a creative description of {name}, in {word_limit} words or less. \n",
    "            Speak directly to {name}.\n",
    "            Give them a point of view.\n",
    "            Do not add anything else.\"\"\"\n",
    "        ),\n",
    "    ]\n",
    "    agent_description = ChatOpenAI(temperature=1.0)(agent_specifier_prompt).content\n",
    "    return agent_description\n",
    "\n",
    "\n",
    "agent_descriptions = {name: generate_agent_description(name) for name in names}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ed0226759c66a59"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for name, description in agent_descriptions.items():\n",
    "    print(description)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b46aaf1ffaea98f2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_system_message(name, description, tools):\n",
    "    return f\"\"\"{conversation_description}\n",
    "    \n",
    "Your name is {name}.\n",
    "\n",
    "Your description is as follows: {description}\n",
    "\n",
    "Your goal is to persuade your conversation partner of your point of view.\n",
    "\n",
    "DO look up information with your tool to refute your partner's claims.\n",
    "DO cite your sources.\n",
    "\n",
    "DO NOT fabricate fake citations.\n",
    "DO NOT cite any source that you did not look up.\n",
    "\n",
    "Do not add anything else.\n",
    "\n",
    "Stop speaking the moment you finish speaking from your perspective.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "agent_system_messages = {\n",
    "    name: generate_system_message(name, description, tools)\n",
    "    for (name, tools), description in zip(names.items(), agent_descriptions.values())\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "725bebba6b7e7bfe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for name, system_message in agent_system_messages.items():\n",
    "    print(name)\n",
    "    print(system_message)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3e3402c4a542398"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "topic_specifier_prompt = [\n",
    "    SystemMessage(content=\"You can make a topic more specific.\"),\n",
    "    HumanMessage(\n",
    "        content=f\"\"\"{topic}\n",
    "        \n",
    "        You are the moderator.\n",
    "        Please make the topic more specific.\n",
    "        Please reply with the specified quest in {word_limit} words or less. \n",
    "        Speak directly to the participants: {*names,}.\n",
    "        Do not add anything else.\"\"\"\n",
    "    ),\n",
    "]\n",
    "specified_topic = ChatOpenAI(temperature=1.0)(topic_specifier_prompt).content\n",
    "\n",
    "print(f\"Original topic:\\n{topic}\\n\")\n",
    "print(f\"Detailed topic:\\n{specified_topic}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1476618203145b0c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# we set `top_k_results`=2 as part of the `tool_kwargs` to prevent results from overflowing the context limit\n",
    "agents = [\n",
    "    DialogueAgentWithTools(\n",
    "        name=name,\n",
    "        system_message=SystemMessage(content=system_message),\n",
    "        model=ChatOpenAI(model_name=\"gpt-4\", temperature=0.2),\n",
    "        tool_names=tools,\n",
    "        top_k_results=2,\n",
    "    )\n",
    "    for (name, tools), system_message in zip(\n",
    "        names.items(), agent_system_messages.values()\n",
    "    )\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a62fa5ad6a6bc6d8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def select_next_speaker(step: int, agents: List[DialogueAgent]) -> int:\n",
    "    idx = (step) % len(agents)\n",
    "    return idx"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "146f978dc5780256"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "max_iters = 6\n",
    "n = 0\n",
    "\n",
    "simulator = DialogueSimulator(agents=agents, selection_function=select_next_speaker)\n",
    "simulator.reset()\n",
    "simulator.inject(\"Moderator\", specified_topic)\n",
    "print(f\"(Moderator): {specified_topic}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "while n < max_iters:\n",
    "    name, message = simulator.step()\n",
    "    print(f\"({name}): {message}\")\n",
    "    print(\"\\n\")\n",
    "    n += 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eab5ab88c791b2fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
